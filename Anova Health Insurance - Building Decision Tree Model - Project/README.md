# ğŸ¥ Anova Health Insurance â€“ Building a Decision Tree Model
### ğŸŒ³ Explainable Machine Learning for Insurance Risk Analytics

---

## ğŸ“Œ Project Overview

**Project Name:** ğŸ¥ **Anova Insurance Health Risk Prediction**  
**Domain:** ğŸ’¼ Health Insurance | ğŸ“Š Risk Analytics  
**Model Type:** ğŸ¤– Supervised Machine Learning  
**Task:** ğŸ§© **Binary Classification**  
**Algorithm:** ğŸŒ³ **Decision Tree**  
**Explainability:** ğŸ” **High (Business-friendly, rule-based)**

---

## ğŸ§­ Business Context

### ğŸ¢ Why This Project Exists
Anova Insurance aims to **optimize health insurance eligibility and premium pricing** by accurately assessing **applicant health risk** using data-driven decisioning.

### ğŸ”‘ Key Business Decisions
- âœ… Insurance eligibility approval  
- ğŸ’° Premium pricing (standard vs risk-adjusted)

### âš ï¸ Risk Focus
- ğŸš« Avoid underpricing high-risk applicants  
- ğŸ¯ Minimize **False Negatives**  
  *(Unhealthy applicants predicted as Healthy)*

---

## ğŸ¯ Problem Statement

### Objective
Build a predictive model that classifies individuals as:

- ğŸŸ¢ **Healthy (0)**
- ğŸ”´ **Unhealthy (1)**

using **health, lifestyle, and medical attributes**.

### Why It Matters
| Applicant Type | Impact | Business Action |
|---------------|--------|-----------------|
| ğŸŸ¢ Healthy | Lower claim risk | ğŸ’¸ Standard / Discounted premium |
| ğŸ”´ Unhealthy | Higher claim risk | âš ï¸ Risk-adjusted premium / Medical review |

---

## ğŸ—‚ï¸ Dataset Overview

**Source:** ğŸ—‚ï¸ Anova Insurance (Synthetic / Training Dataset)

**Shape**
- **Rows:** 10,000  
- **Columns:** 20  

### ğŸ¯ Target Variable
**Name:** `Target`

- `0` â†’ ğŸŸ¢ Healthy  
- `1` â†’ ğŸ”´ Unhealthy  

### â— Data Challenges
- â— Missing values (especially for older individuals)
- âŒ Negative age values
- ğŸ”„ Mixed feature types (numeric, ordinal, nominal)

---

## ğŸ§¬ Feature Breakdown

### ğŸ”¢ Numerical Features
- ğŸ‚ Age  
- âš–ï¸ BMI  
- ğŸ’‰ Blood_Pressure  
- ğŸ§ª Cholesterol  
- ğŸ¬ Glucose_Level  
- â¤ï¸ Heart_Rate  
- ğŸ˜´ Sleep_Hours  
- ğŸƒ Exercise_Hours  
- ğŸš° Water_Intake  
- ğŸ˜– Stress_Level  

### ğŸ” Ordinal Categorical (0 < 1 < 2)
- ğŸš¬ Smoking  
- ğŸº Alcohol  
- ğŸ¥— Diet  
- ğŸ§  MentalHealth  
- ğŸ‹ï¸ PhysicalActivity  
- ğŸ¥ MedicalHistory  
- ğŸ¤§ Allergies  

### ğŸ§© Nominal Categorical
- ğŸ½ï¸ Diet_Type â†’ Vegetarian, Non-Vegetarian, Vegan  
- ğŸ©¸ Blood_Group â†’ A, B, AB, O  

---

## ğŸ§  Machine Learning Objective

**Task Type:** ğŸ§  Classification

### ğŸ”® Prediction Output
- `0` â†’ ğŸŸ¢ Healthy  
- `1` â†’ ğŸ”´ Unhealthy  

### ğŸ¯ Evaluation Priority
**Primary Metric:** ğŸš¨ **Recall (Unhealthy)**

> âš ï¸ False Negatives lead to **underpriced high-risk policies**,  
> which is financially dangerous for insurers.

---

## ğŸ”„ End-to-End Workflow

### ğŸ“¥ Step 1: Data Ingestion
- ğŸ“‚ Load dataset  
- ğŸ” Validate schema & shape  
- âœ… Ensure target âˆˆ `{0,1}`  

---

### ğŸ” Step 2: Exploratory Data Analysis (EDA)
- ğŸ“Š Target distribution  
- ğŸ“ˆ Numeric feature statistics  
- ğŸ§© Missing value analysis  
- ğŸ”— Correlation with target  
- ğŸ“Œ Category frequency checks  

**Outputs**
- ğŸ’¡ Risk indicator hypotheses  
- ğŸ§  Data quality insights  

---

### ğŸ§¹ Step 3: Data Cleaning
- âŒ Convert negative ages â†’ `NaN`  
- ğŸš« Remove impossible values (BMI â‰¤ 0, invalid sleep hours)  
- ğŸ› ï¸ Handle missing values:
  - **Numerical:** Median  
  - **Ordinal:** Mode  
  - **Nominal:** Mode / `"Unknown"`  

---

### ğŸ—ï¸ Step 4: Feature Engineering
- ğŸ”¢ Preserve ordinal order (0 < 1 < 2)  
- ğŸ§© One-hot encode nominal features  
- âœ¨ Optional domain features:
  - âš–ï¸ BMI category  
  - ğŸ’‰ Blood pressure category  
  - ğŸ§¬ Lifestyle risk score  

---

### ğŸ”€ Step 5: Trainâ€“Test Split
- **Split Ratio:** 80 / 20  
- **Stratify:** Target  
- **Random State:** Fixed  

---

### ğŸŒ± Step 6: Baseline Decision Tree
**Purpose:** ğŸ§ª Establish benchmark performance

- Default depth  
- Fixed random state  

---

### ğŸ›ï¸ Step 7: Hyperparameter Tuning
**Goal:** ğŸ›¡ï¸ Control overfitting

**Parameters Tuned**
- ğŸŒ³ `max_depth`  
- ğŸ”€ `min_samples_split`  
- ğŸƒ `min_samples_leaf`  
- âš–ï¸ `class_weight`  

**Strategy**
- ğŸ” GridSearchCV / RandomizedSearchCV  
- ğŸ¯ Optimize **Recall (Unhealthy)**  

---

### ğŸ“ Step 8: Model Evaluation

**Technical Metrics**
- ğŸ“‰ Confusion Matrix  
- ğŸ“Š Accuracy  
- ğŸ¯ Precision (Unhealthy)  
- ğŸš¨ Recall (Unhealthy)  
- ğŸ§® F1-score  
- ğŸ“ˆ ROC-AUC  

**Insurance Lens**
- ğŸš« Track False Negatives explicitly  
- ğŸ”§ Adjust thresholds if required  

---

### ğŸ” Step 9: Model Interpretability
- â­ Feature importance ranking  
- ğŸŒ³ Decision Tree visualization  
- ğŸ—£ï¸ Human-readable IFâ€“THEN rules  

**Example Rule**
> IF ğŸ¬ *Glucose_Level is high* AND ğŸ¥ *MedicalHistory is severe*  
> THEN applicant is ğŸ”´ **Unhealthy**

---

### ğŸ§® Step 10: Risk Banding & Premium Mapping

**Method:** ğŸ“Š Probability-based (Recommended)

| Risk Band | Condition | Action |
|----------|-----------|--------|
| ğŸŸ¢ Low | p < 0.30 | ğŸ’¸ Standard / Discount |
| ğŸŸ¡ Medium | 0.30 â€“ 0.60 | âš ï¸ Mild loading |
| ğŸ”´ High | â‰¥ 0.60 | ğŸš‘ Medical review / Higher premium |

---

## ğŸš€ Deployment Readiness

**Usage Notes**
- ğŸ¤ Model supports decisions, not final approval  
- ğŸ‘©â€âš–ï¸ Underwriters retain authority  

**Monitoring**
- ğŸ“‰ Prediction drift tracking  
- ğŸš¨ False negative trend review  
- ğŸ” Periodic retraining  

---

## âœ… Success Criteria

### ğŸ§ª Technical
- ğŸ¯ High recall for Unhealthy  
- ğŸ“ˆ Stable ROC-AUC  
- ğŸ›¡ï¸ Controlled overfitting  

### ğŸ’¼ Business
- ğŸ’° Better premium differentiation  
- ğŸ” Reduced underwriting risk  
- ğŸ” Explainable & auditable decisions  

---

## ğŸ“¦ Deliverables
- ğŸ“‚ Cleaned dataset  
- ğŸ“Š EDA insights  
- ğŸŒ³ Trained Decision Tree model  
- ğŸ“ Evaluation metrics  
- ğŸ§  Interpretable rules  
- ğŸ’¸ Risk band & premium mapping  
- ğŸš€ Deployment-ready notebook  

---

## ğŸ”® Next Improvements
- ğŸŒ² Random Forest / âš¡ Gradient Boosting comparison  
- ğŸ¯ Probability calibration  
- âš–ï¸ Bias & fairness checks  
