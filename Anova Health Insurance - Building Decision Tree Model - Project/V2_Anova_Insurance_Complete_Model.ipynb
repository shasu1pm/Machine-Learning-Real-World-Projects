{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Decision Tree Model For Anova Insurance\n",
    "\n",
    "## Business Objective\n",
    "Anova Insurance wants to optimize premium pricing and eligibility decisions by assessing applicant health risk using machine learning.\n",
    "\n",
    "**Target Prediction:**\n",
    "- 0 = Healthy (lower risk, standard/discounted premiums)\n",
    "- 1 = Unhealthy (higher risk, risk-adjusted premiums)\n",
    "\n",
    "**Business Impact:**\n",
    "- Better premium differentiation\n",
    "- Reduced underwriting risk\n",
    "- Scalable health scoring system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Data Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from google.colab import files\n",
    "import io\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(\"üìä Ready for data analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data file (Excel or CSV)\n",
    "print(\"üìÅ Please upload your Anova Insurance dataset (Excel or CSV format)\")\n",
    "print(\"Expected columns: Age, BMI, Blood_Pressure, Cholesterol, Glucose_Level, Heart_Rate,\")\n",
    "print(\"Sleep_Hours, Exercise_Hours, Water_Intake, Stress_Level, Smoking, Alcohol,\")\n",
    "print(\"Diet, MentalHealth, PhysicalActivity, MedicalHistory, Allergies, Diet_Type, Blood_Group, Target\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Load the uploaded file\n",
    "filename = list(uploaded.keys())[0]\n",
    "print(f\"\\nüìÇ Loading file: {filename}\")\n",
    "\n",
    "if filename.endswith('.csv'):\n",
    "    df = pd.read_csv(io.BytesIO(uploaded[filename]))\n",
    "elif filename.endswith(('.xlsx', '.xls')):\n",
    "    df = pd.read_excel(io.BytesIO(uploaded[filename]))\n",
    "else:\n",
    "    raise ValueError(\"Please upload a CSV or Excel file\")\n",
    "\n",
    "print(f\"‚úÖ Data loaded successfully!\")\n",
    "print(f\"üìä Dataset shape: {df.shape}\")\n",
    "print(f\"üéØ Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "print(\"=\" * 50)\n",
    "print(\"üìä DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\nüìã Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nüéØ Target Distribution:\")\n",
    "target_dist = df['Target'].value_counts().sort_index()\n",
    "print(target_dist)\n",
    "print(f\"\\nClass Balance:\")\n",
    "print(f\"Healthy (0): {target_dist[0]/len(df)*100:.1f}%\")\n",
    "print(f\"Unhealthy (1): {target_dist[1]/len(df)*100:.1f}%\")\n",
    "\n",
    "# Check for class imbalance\n",
    "imbalance_ratio = target_dist.min() / target_dist.max()\n",
    "if imbalance_ratio < 0.8:\n",
    "    print(f\"‚ö†Ô∏è Class imbalance detected (ratio: {imbalance_ratio:.2f})\")\n",
    "    print(\"Will use class_weight='balanced' in model training\")\n",
    "else:\n",
    "    print(f\"‚úÖ Classes are reasonably balanced (ratio: {imbalance_ratio:.2f})\")\n",
    "\n",
    "# Define feature categories\n",
    "numerical_cols = ['Age', 'BMI', 'Blood_Pressure', 'Cholesterol', 'Glucose_Level', \n",
    "                  'Heart_Rate', 'Sleep_Hours', 'Exercise_Hours', 'Water_Intake', 'Stress_Level']\n",
    "ordinal_cols = ['Smoking', 'Alcohol', 'Diet', 'MentalHealth', 'PhysicalActivity', 'MedicalHistory', 'Allergies']\n",
    "nominal_cols = ['Diet_Type', 'Blood_Group']\n",
    "\n",
    "existing_numerical = [col for col in numerical_cols if col in df.columns]\n",
    "existing_ordinal = [col for col in ordinal_cols if col in df.columns]\n",
    "existing_nominal = [col for col in nominal_cols if col in df.columns]\n",
    "\n",
    "print(f\"\\nüìä Feature Categories:\")\n",
    "print(f\"Numerical: {existing_numerical}\")\n",
    "print(f\"Ordinal: {existing_ordinal}\")\n",
    "print(f\"Nominal: {existing_nominal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values and data quality analysis\n",
    "print(\"=\" * 50)\n",
    "print(\"üîç DATA QUALITY ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing_data,\n",
    "    'Missing_Percentage': missing_percent\n",
    "}).sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "print(\"Missing Values Summary:\")\n",
    "print(missing_df[missing_df['Missing_Count'] > 0])\n",
    "\n",
    "if missing_data.sum() > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Total missing values: {missing_data.sum()}\")\n",
    "    # Visualize missing values\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(df.isnull(), cbar=True, yticklabels=False, cmap='viridis')\n",
    "    plt.title('Missing Values Heatmap')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚úÖ No missing values found!\")\n",
    "\n",
    "# Check for data quality issues\n",
    "if 'Age' in df.columns:\n",
    "    negative_ages = (df['Age'] < 0).sum()\n",
    "    if negative_ages > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è Found {negative_ages} negative age values - will be cleaned\")\n",
    "\n",
    "# Summary statistics for numerical features\n",
    "if existing_numerical:\n",
    "    print(\"\\nüìä Numerical Features Summary:\")\n",
    "    print(df[existing_numerical].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning\n",
    "print(\"=\" * 50)\n",
    "print(\"üßπ DATA CLEANING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "df_clean = df.copy()\n",
    "cleaning_log = []\n",
    "\n",
    "# Fix negative ages\n",
    "if 'Age' in df_clean.columns:\n",
    "    negative_ages_count = (df_clean['Age'] < 0).sum()\n",
    "    if negative_ages_count > 0:\n",
    "        print(f\"üîß Fixing {negative_ages_count} negative age values...\")\n",
    "        df_clean.loc[df_clean['Age'] < 0, 'Age'] = np.nan\n",
    "        cleaning_log.append(f\"Converted {negative_ages_count} negative ages to NaN\")\n",
    "\n",
    "# Handle impossible values\n",
    "if 'BMI' in df_clean.columns:\n",
    "    invalid_bmi = ((df_clean['BMI'] <= 0) | (df_clean['BMI'] > 100)).sum()\n",
    "    if invalid_bmi > 0:\n",
    "        df_clean.loc[(df_clean['BMI'] <= 0) | (df_clean['BMI'] > 100), 'BMI'] = np.nan\n",
    "        cleaning_log.append(f\"Fixed {invalid_bmi} impossible BMI values\")\n",
    "\n",
    "# Handle missing values with imputation\n",
    "print(\"\\nüîß Handling missing values with imputation...\")\n",
    "\n",
    "# Numerical imputation (median)\n",
    "numerical_imputer = SimpleImputer(strategy='median')\n",
    "for col in existing_numerical:\n",
    "    if df_clean[col].isnull().sum() > 0:\n",
    "        original_missing = df_clean[col].isnull().sum()\n",
    "        df_clean[col] = numerical_imputer.fit_transform(df_clean[[col]]).ravel()\n",
    "        cleaning_log.append(f\"Imputed {original_missing} missing values in {col} with median\")\n",
    "        print(f\"  üìä {col}: imputed {original_missing} values with median\")\n",
    "\n",
    "# Categorical imputation (mode)\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "all_categorical = existing_ordinal + existing_nominal\n",
    "for col in all_categorical:\n",
    "    if df_clean[col].isnull().sum() > 0:\n",
    "        original_missing = df_clean[col].isnull().sum()\n",
    "        df_clean[col] = categorical_imputer.fit_transform(df_clean[[col]]).ravel()\n",
    "        cleaning_log.append(f\"Imputed {original_missing} missing values in {col} with mode\")\n",
    "        print(f\"  üè∑Ô∏è {col}: imputed {original_missing} values with mode\")\n",
    "\n",
    "print(f\"\\n‚úÖ Data cleaning completed!\")\n",
    "print(f\"üìä Dataset shape after cleaning: {df_clean.shape}\")\n",
    "if cleaning_log:\n",
    "    print(\"\\nüìã Cleaning operations performed:\")\n",
    "    for i, operation in enumerate(cleaning_log, 1):\n",
    "        print(f\"{i}. {operation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "print(\"=\" * 50)\n",
    "print(\"‚öôÔ∏è FEATURE ENGINEERING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "df_features = df_clean.copy()\n",
    "engineering_log = []\n",
    "\n",
    "# Create BMI categories\n",
    "if 'BMI' in df_features.columns:\n",
    "    def categorize_bmi(bmi):\n",
    "        if bmi < 18.5: return 0  # Underweight\n",
    "        elif bmi < 25: return 1  # Normal\n",
    "        elif bmi < 30: return 2  # Overweight\n",
    "        else: return 3  # Obese\n",
    "    \n",
    "    df_features['BMI_Category'] = df_features['BMI'].apply(categorize_bmi)\n",
    "    engineering_log.append(\"Created BMI_Category\")\n",
    "    print(\"‚úÖ Created BMI categories\")\n",
    "\n",
    "# Create Blood Pressure categories\n",
    "if 'Blood_Pressure' in df_features.columns:\n",
    "    def categorize_bp(bp):\n",
    "        if bp < 120: return 0  # Normal\n",
    "        elif bp < 140: return 1  # Elevated\n",
    "        else: return 2  # High\n",
    "    \n",
    "    df_features['BP_Category'] = df_features['Blood_Pressure'].apply(categorize_bp)\n",
    "    engineering_log.append(\"Created BP_Category\")\n",
    "    print(\"‚úÖ Created Blood Pressure categories\")\n",
    "\n",
    "# Create Glucose categories\n",
    "if 'Glucose_Level' in df_features.columns:\n",
    "    def categorize_glucose(glucose):\n",
    "        if glucose < 100: return 0  # Normal\n",
    "        elif glucose < 126: return 1  # Pre-diabetic\n",
    "        else: return 2  # Diabetic-like\n",
    "    \n",
    "    df_features['Glucose_Category'] = df_features['Glucose_Level'].apply(categorize_glucose)\n",
    "    engineering_log.append(\"Created Glucose_Category\")\n",
    "    print(\"‚úÖ Created Glucose categories\")\n",
    "\n",
    "# Create Lifestyle Score\n",
    "lifestyle_factors = ['Smoking', 'Alcohol', 'Diet', 'PhysicalActivity']\n",
    "available_lifestyle = [col for col in lifestyle_factors if col in df_features.columns]\n",
    "\n",
    "if len(available_lifestyle) >= 2:\n",
    "    df_features['Lifestyle_Score'] = df_features[available_lifestyle].sum(axis=1)\n",
    "    engineering_log.append(f\"Created Lifestyle_Score from: {available_lifestyle}\")\n",
    "    print(f\"‚úÖ Created Lifestyle Score from {len(available_lifestyle)} factors\")\n",
    "\n",
    "# One-hot encode nominal categorical variables\n",
    "nominal_to_encode = [col for col in existing_nominal if col in df_features.columns]\n",
    "if nominal_to_encode:\n",
    "    print(f\"\\nüî§ One-hot encoding: {nominal_to_encode}\")\n",
    "    for col in nominal_to_encode:\n",
    "        dummies = pd.get_dummies(df_features[col], prefix=col, drop_first=True)\n",
    "        df_features = pd.concat([df_features, dummies], axis=1)\n",
    "        df_features.drop(col, axis=1, inplace=True)\n",
    "        engineering_log.append(f\"One-hot encoded {col}\")\n",
    "        print(f\"  ‚úÖ {col} -> {len(dummies.columns)} binary features\")\n",
    "\n",
    "# Keep ordinal features as integers\n",
    "ordinal_to_keep = [col for col in existing_ordinal if col in df_features.columns]\n",
    "if ordinal_to_keep:\n",
    "    for col in ordinal_to_keep:\n",
    "        df_features[col] = df_features[col].astype(int)\n",
    "\n",
    "print(f\"\\nüìä Feature engineering completed!\")\n",
    "print(f\"üìà Dataset shape: {df_features.shape}\")\n",
    "print(f\"üéØ New features created: {df_features.shape[1] - df_clean.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "print(\"=\" * 50)\n",
    "print(\"‚úÇÔ∏è TRAIN/TEST SPLIT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Separate features and target\n",
    "X = df_features.drop('Target', axis=1)\n",
    "y = df_features['Target']\n",
    "\n",
    "print(f\"üìä Features shape: {X.shape}\")\n",
    "print(f\"üéØ Target shape: {y.shape}\")\n",
    "\n",
    "# Check class distribution\n",
    "target_counts = y.value_counts().sort_index()\n",
    "minority_class_ratio = min(target_counts) / max(target_counts)\n",
    "use_class_weight = minority_class_ratio < 0.8\n",
    "\n",
    "print(f\"\\nüéØ Target distribution:\")\n",
    "for target_val, count in target_counts.items():\n",
    "    label = \"Healthy\" if target_val == 0 else \"Unhealthy\"\n",
    "    print(f\"  {label} ({target_val}): {count} ({count/len(y)*100:.1f}%)\")\n",
    "\n",
    "if use_class_weight:\n",
    "    print(f\"\\n‚öñÔ∏è Class imbalance detected - will use balanced class weights\")\n",
    "\n",
    "# Perform stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Split completed!\")\n",
    "print(f\"üìä Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"üìä Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Decision Tree Model\n",
    "print(\"=\" * 50)\n",
    "print(\"üå≥ BASELINE DECISION TREE MODEL\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create and train baseline model\n",
    "baseline_params = {\n",
    "    'random_state': 42,\n",
    "    'class_weight': 'balanced' if use_class_weight else None\n",
    "}\n",
    "\n",
    "baseline_dt = DecisionTreeClassifier(**baseline_params)\n",
    "baseline_dt.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_baseline = baseline_dt.predict(X_train)\n",
    "y_test_pred_baseline = baseline_dt.predict(X_test)\n",
    "y_test_proba_baseline = baseline_dt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate baseline model\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred_baseline)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_baseline)\n",
    "test_precision = precision_score(y_test, y_test_pred_baseline)\n",
    "test_recall = recall_score(y_test, y_test_pred_baseline)\n",
    "test_f1 = f1_score(y_test, y_test_pred_baseline)\n",
    "test_auc = roc_auc_score(y_test, y_test_proba_baseline)\n",
    "\n",
    "print(f\"\\nüìä BASELINE MODEL PERFORMANCE:\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy:     {test_accuracy:.4f}\")\n",
    "print(f\"Precision:         {test_precision:.4f}\")\n",
    "print(f\"Recall:            {test_recall:.4f} ‚≠ê\")\n",
    "print(f\"F1-Score:          {test_f1:.4f}\")\n",
    "print(f\"ROC-AUC:           {test_auc:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_baseline = confusion_matrix(y_test, y_test_pred_baseline)\n",
    "print(f\"\\nüìä Confusion Matrix:\")\n",
    "print(f\"                 Predicted\")\n",
    "print(f\"Actual    Healthy  Unhealthy\")\n",
    "print(f\"Healthy      {cm_baseline[0,0]:3d}      {cm_baseline[0,1]:3d}\")\n",
    "print(f\"Unhealthy    {cm_baseline[1,0]:3d}      {cm_baseline[1,1]:3d}\")\n",
    "\n",
    "# Store baseline results\n",
    "baseline_results = {\n",
    "    'accuracy': test_accuracy,\n",
    "    'precision': test_precision,\n",
    "    'recall': test_recall,\n",
    "    'f1': test_f1,\n",
    "    'auc': test_auc,\n",
    "    'false_negatives': cm_baseline[1, 0],\n",
    "    'tree_depth': baseline_dt.get_depth(),\n",
    "    'n_leaves': baseline_dt.get_n_leaves()\n",
    "}\n",
    "\n",
    "print(f\"\\n‚úÖ Baseline model trained and evaluated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "print(\"=\" * 50)\n",
    "print(\"üîß HYPERPARAMETER TUNING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10, None],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "print(f\"üéõÔ∏è Testing {np.prod([len(v) for v in param_grid.values()])} parameter combinations\")\n",
    "print(f\"üéØ Optimizing for recall (insurance priority)\")\n",
    "\n",
    "# Create base model\n",
    "base_model = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    class_weight='balanced' if use_class_weight else None\n",
    ")\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='recall',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\nüöÄ Starting hyperparameter tuning...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best model\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "best_cv_score = grid_search.best_score_\n",
    "\n",
    "print(f\"\\nüèÜ BEST PARAMETERS:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\nüìä Best CV Recall Score: {best_cv_score:.4f}\")\n",
    "print(f\"üìà Improvement over baseline: {best_cv_score - baseline_results['recall']:+.4f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Hyperparameter tuning completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model Evaluation\n",
    "print(\"=\" * 50)\n",
    "print(\"üìä FINAL MODEL EVALUATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Make predictions with tuned model\n",
    "y_train_pred_tuned = best_model.predict(X_train)\n",
    "y_test_pred_tuned = best_model.predict(X_test)\n",
    "y_test_proba_tuned = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "train_accuracy_tuned = accuracy_score(y_train, y_train_pred_tuned)\n",
    "test_accuracy_tuned = accuracy_score(y_test, y_test_pred_tuned)\n",
    "test_precision_tuned = precision_score(y_test, y_test_pred_tuned)\n",
    "test_recall_tuned = recall_score(y_test, y_test_pred_tuned)\n",
    "test_f1_tuned = f1_score(y_test, y_test_pred_tuned)\n",
    "test_auc_tuned = roc_auc_score(y_test, y_test_proba_tuned)\n",
    "\n",
    "# Performance comparison\n",
    "print(\"üìà PERFORMANCE COMPARISON\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"{'Metric':<12} {'Baseline':<10} {'Tuned':<10} {'Change':<10}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "metrics_comparison = [\n",
    "    ('Accuracy', baseline_results['accuracy'], test_accuracy_tuned),\n",
    "    ('Precision', baseline_results['precision'], test_precision_tuned),\n",
    "    ('Recall', baseline_results['recall'], test_recall_tuned),\n",
    "    ('F1-Score', baseline_results['f1'], test_f1_tuned),\n",
    "    ('ROC-AUC', baseline_results['auc'], test_auc_tuned)\n",
    "]\n",
    "\n",
    "for metric, baseline_val, tuned_val in metrics_comparison:\n",
    "    change = tuned_val - baseline_val\n",
    "    print(f\"{metric:<12} {baseline_val:<10.4f} {tuned_val:<10.4f} {change:+10.4f}\")\n",
    "\n",
    "# Confusion matrix analysis\n",
    "cm_tuned = confusion_matrix(y_test, y_test_pred_tuned)\n",
    "tn, fp, fn, tp = cm_tuned.ravel()\n",
    "\n",
    "print(f\"\\nüè• INSURANCE RISK ANALYSIS\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"True Negatives (Healthy ‚Üí Healthy):     {tn:3d} ‚úÖ\")\n",
    "print(f\"False Positives (Healthy ‚Üí Unhealthy):  {fp:3d} ‚ö†Ô∏è\")\n",
    "print(f\"False Negatives (Unhealthy ‚Üí Healthy):  {fn:3d} üö®\")\n",
    "print(f\"True Positives (Unhealthy ‚Üí Unhealthy): {tp:3d} ‚úÖ\")\n",
    "\n",
    "false_negative_rate = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\n",
    "print(f\"\\nüìä Risk Ratios:\")\n",
    "print(f\"False Negative Rate: {false_negative_rate:.2%} (unhealthy missed)\")\n",
    "print(f\"False Positive Rate: {false_positive_rate:.2%} (healthy misclassified)\")\n",
    "\n",
    "# Store final results\n",
    "final_results = {\n",
    "    'accuracy': test_accuracy_tuned,\n",
    "    'precision': test_precision_tuned,\n",
    "    'recall': test_recall_tuned,\n",
    "    'f1': test_f1_tuned,\n",
    "    'auc': test_auc_tuned,\n",
    "    'false_negatives': fn,\n",
    "    'false_positives': fp,\n",
    "    'false_negative_rate': false_negative_rate,\n",
    "    'false_positive_rate': false_positive_rate\n",
    "}\n",
    "\n",
    "print(f\"\\n‚úÖ Final model evaluation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Model Interpretability and Risk Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance and Interpretability\n",
    "print(\"=\" * 50)\n",
    "print(\"üîç MODEL INTERPRETABILITY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Feature importance analysis\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': best_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"üéØ TOP 10 FEATURE IMPORTANCE:\")\n",
    "print(\"-\" * 35)\n",
    "for i, (_, row) in enumerate(feature_importance_df.head(10).iterrows(), 1):\n",
    "    print(f\"{i:2d}. {row['Feature']:<20} {row['Importance']:.4f}\")\n",
    "\n",
    "# Extract decision rules\n",
    "tree_rules = export_text(best_model, feature_names=list(X.columns), max_depth=3)\n",
    "print(f\"\\nüå≥ DECISION TREE RULES (Simplified):\")\n",
    "print(tree_rules[:1000] + \"...\" if len(tree_rules) > 1000 else tree_rules)\n",
    "\n",
    "# Create business rules\n",
    "top_features = feature_importance_df.head(5)['Feature'].tolist()\n",
    "business_rules = [\n",
    "    f\"High {top_features[0]} indicates elevated health risk\",\n",
    "    f\"Combination of high {top_features[0]} and {top_features[1]} requires medical review\",\n",
    "    f\"{top_features[2]} above threshold suggests increased risk\",\n",
    "    f\"Multiple risk factors (3+) require specialized underwriting\",\n",
    "    f\"Age combined with lifestyle factors determines risk level\"\n",
    "]\n",
    "\n",
    "print(f\"\\nüìù BUSINESS RULES GENERATED:\")\n",
    "for i, rule in enumerate(business_rules, 1):\n",
    "    print(f\"{i}. {rule}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Model interpretability analysis completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk Bands and Premium Mapping\n",
    "print(\"=\" * 50)\n",
    "print(\"üéØ RISK BANDS & PREMIUM MAPPING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get probability predictions\n",
    "test_probabilities = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Define risk bands\n",
    "def assign_risk_band(probability):\n",
    "    if probability < 0.30:\n",
    "        return 'Low Risk'\n",
    "    elif probability < 0.60:\n",
    "        return 'Medium Risk'\n",
    "    else:\n",
    "        return 'High Risk'\n",
    "\n",
    "# Apply risk banding\n",
    "risk_bands = [assign_risk_band(prob) for prob in test_probabilities]\n",
    "risk_band_df = pd.DataFrame({\n",
    "    'Probability': test_probabilities,\n",
    "    'Risk_Band': risk_bands,\n",
    "    'Actual_Target': y_test.values,\n",
    "    'Predicted_Target': y_test_pred_tuned\n",
    "})\n",
    "\n",
    "# Risk band distribution\n",
    "risk_distribution = pd.Series(risk_bands).value_counts()\n",
    "total_samples = len(risk_bands)\n",
    "\n",
    "print(\"üìä RISK BAND DISTRIBUTION:\")\n",
    "for risk_level in ['Low Risk', 'Medium Risk', 'High Risk']:\n",
    "    count = risk_distribution.get(risk_level, 0)\n",
    "    percentage = (count / total_samples) * 100\n",
    "    print(f\"{risk_level:12}: {count:4d} samples ({percentage:5.1f}%)\")\n",
    "\n",
    "# Premium mapping logic\n",
    "base_premium = 1000\n",
    "premium_mapping = {\n",
    "    'Low Risk': {\n",
    "        'multiplier': 0.85,\n",
    "        'action': 'Standard/Discount Eligible',\n",
    "        'description': 'Healthy profile, low claim probability'\n",
    "    },\n",
    "    'Medium Risk': {\n",
    "        'multiplier': 1.0,\n",
    "        'action': 'Standard Premium',\n",
    "        'description': 'Moderate risk, standard underwriting'\n",
    "    },\n",
    "    'High Risk': {\n",
    "        'multiplier': 1.35,\n",
    "        'action': 'Premium Loading/Medical Review',\n",
    "        'description': 'High risk profile, detailed assessment needed'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"\\nüí∞ PREMIUM MAPPING (Base: ${base_premium:,}):\")\n",
    "for risk_level, mapping in premium_mapping.items():\n",
    "    premium = base_premium * mapping['multiplier']\n",
    "    change = (mapping['multiplier'] - 1) * 100\n",
    "    print(f\"\\n{risk_level}:\")\n",
    "    print(f\"  Premium: ${premium:,.0f} ({change:+.0f}%)\")\n",
    "    print(f\"  Action: {mapping['action']}\")\n",
    "    print(f\"  Rationale: {mapping['description']}\")\n",
    "\n",
    "# Calculate premiums\n",
    "risk_band_df['Premium_Multiplier'] = risk_band_df['Risk_Band'].map(\n",
    "    {level: mapping['multiplier'] for level, mapping in premium_mapping.items()}\n",
    ")\n",
    "risk_band_df['Annual_Premium'] = base_premium * risk_band_df['Premium_Multiplier']\n",
    "\n",
    "# Business impact\n",
    "total_premium = risk_band_df['Annual_Premium'].sum()\n",
    "standard_premium_total = base_premium * len(risk_band_df)\n",
    "premium_difference = total_premium - standard_premium_total\n",
    "\n",
    "print(f\"\\nüìà BUSINESS IMPACT:\")\n",
    "print(f\"Risk-Adjusted Premium Total: ${total_premium:,.0f}\")\n",
    "print(f\"Standard Premium Total:      ${standard_premium_total:,.0f}\")\n",
    "print(f\"Net Impact:                  ${premium_difference:+,.0f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Risk banding and premium mapping completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Export Results and Download Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Results\n",
    "print(\"=\" * 50)\n",
    "print(\"üìÅ EXPORTING RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Prepare comprehensive predictions data\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Sample_ID': range(1, len(X_test) + 1),\n",
    "    'Actual_Health_Status': y_test.values,\n",
    "    'Actual_Health_Label': ['Healthy' if x == 0 else 'Unhealthy' for x in y_test.values],\n",
    "    'Predicted_Health_Status': y_test_pred_tuned,\n",
    "    'Predicted_Health_Label': ['Healthy' if x == 0 else 'Unhealthy' for x in y_test_pred_tuned],\n",
    "    'Prediction_Probability': y_test_proba_tuned,\n",
    "    'Risk_Band': risk_bands,\n",
    "    'Premium_Multiplier': risk_band_df['Premium_Multiplier'].values,\n",
    "    'Annual_Premium_USD': risk_band_df['Annual_Premium'].values,\n",
    "    'Prediction_Correct': (y_test.values == y_test_pred_tuned).astype(int),\n",
    "    'Underwriting_Action': [premium_mapping[band]['action'] for band in risk_bands]\n",
    "})\n",
    "\n",
    "# Add top feature values\n",
    "top_5_features = feature_importance_df.head(5)['Feature'].tolist()\n",
    "for feature in top_5_features:\n",
    "    if feature in X_test.columns:\n",
    "        predictions_df[f'Feature_{feature}'] = X_test[feature].values\n",
    "\n",
    "# Prepare model summary\n",
    "model_summary_df = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Model Type', 'Training Samples', 'Test Samples', 'Number of Features',\n",
    "        'Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1-Score', 'ROC-AUC',\n",
    "        'False Negative Rate', 'False Positive Rate', 'Tree Depth', 'Number of Leaves',\n",
    "        'Low Risk Percentage', 'Medium Risk Percentage', 'High Risk Percentage',\n",
    "        'Average Premium', 'Business Rules Generated'\n",
    "    ],\n",
    "    'Value': [\n",
    "        'Decision Tree Classifier', len(X_train), len(X_test), X.shape[1],\n",
    "        f\"{final_results['accuracy']:.4f}\", f\"{final_results['precision']:.4f}\",\n",
    "        f\"{final_results['recall']:.4f}\", f\"{final_results['f1']:.4f}\",\n",
    "        f\"{final_results['auc']:.4f}\", f\"{final_results['false_negative_rate']:.4f}\",\n",
    "        f\"{final_results['false_positive_rate']:.4f}\", best_model.get_depth(),\n",
    "        best_model.get_n_leaves(),\n",
    "        f\"{(risk_band_df['Risk_Band'] == 'Low Risk').mean():.1%}\",\n",
    "        f\"{(risk_band_df['Risk_Band'] == 'Medium Risk').mean():.1%}\",\n",
    "        f\"{(risk_band_df['Risk_Band'] == 'High Risk').mean():.1%}\",\n",
    "        f\"${risk_band_df['Annual_Premium'].mean():.0f}\", len(business_rules)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Prepare success criteria\n",
    "success_criteria_df = pd.DataFrame({\n",
    "    'Criterion': [\n",
    "        'Accuracy Threshold (‚â•0.75)', 'Recall Threshold (‚â•0.70)', 'Precision Threshold (‚â•0.65)',\n",
    "        'ROC-AUC Threshold (‚â•0.75)', 'False Negative Rate (‚â§0.25)', 'Risk Bands Created (‚â•3)',\n",
    "        'Business Rules Generated (‚â•5)', 'Model Interpretability'\n",
    "    ],\n",
    "    'Target': [0.75, 0.70, 0.65, 0.75, 0.25, 3, 5, 'High'],\n",
    "    'Actual': [\n",
    "        final_results['accuracy'], final_results['recall'], final_results['precision'],\n",
    "        final_results['auc'], final_results['false_negative_rate'], len(risk_distribution),\n",
    "        len(business_rules), 'High'\n",
    "    ],\n",
    "    'Status': [\n",
    "        'PASS' if final_results['accuracy'] >= 0.75 else 'FAIL',\n",
    "        'PASS' if final_results['recall'] >= 0.70 else 'FAIL',\n",
    "        'PASS' if final_results['precision'] >= 0.65 else 'FAIL',\n",
    "        'PASS' if final_results['auc'] >= 0.75 else 'FAIL',\n",
    "        'PASS' if final_results['false_negative_rate'] <= 0.25 else 'FAIL',\n",
    "        'PASS' if len(risk_distribution) >= 3 else 'FAIL',\n",
    "        'PASS' if len(business_rules) >= 5 else 'FAIL',\n",
    "        'PASS'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(f\"‚úÖ Data prepared for export!\")\n",
    "print(f\"üìä Predictions: {len(predictions_df)} samples\")\n",
    "print(f\"üìã Model Summary: {len(model_summary_df)} metrics\")\n",
    "print(f\"‚úÖ Success Criteria: {len(success_criteria_df)} criteria\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and Download Excel File\n",
    "print(\"üìù Creating Excel file with multiple sheets...\")\n",
    "\n",
    "# Create Excel file\n",
    "with pd.ExcelWriter('Anova_Insurance_Decision_Tree_Results.xlsx', engine='openpyxl') as writer:\n",
    "    # Main sheets as requested\n",
    "    predictions_df.to_excel(writer, sheet_name='1_Decision Tree Model For Anova Insurance', index=False)\n",
    "    success_criteria_df.to_excel(writer, sheet_name='2_Decision Tree Success Criteria', index=False)\n",
    "    \n",
    "    # Additional analysis sheets\n",
    "    model_summary_df.to_excel(writer, sheet_name='Model Summary', index=False)\n",
    "    feature_importance_df.to_excel(writer, sheet_name='Feature Importance', index=False)\n",
    "    \n",
    "    # Business rules\n",
    "    business_rules_df = pd.DataFrame({\n",
    "        'Rule_ID': range(1, len(business_rules) + 1),\n",
    "        'Business_Rule': business_rules\n",
    "    })\n",
    "    business_rules_df.to_excel(writer, sheet_name='Business Rules', index=False)\n",
    "    \n",
    "    # Risk analysis\n",
    "    risk_analysis = risk_band_df.groupby('Risk_Band').agg({\n",
    "        'Actual_Target': ['count', 'mean'],\n",
    "        'Probability': 'mean',\n",
    "        'Annual_Premium': 'mean'\n",
    "    }).round(4)\n",
    "    risk_analysis.columns = ['Sample_Count', 'Actual_Unhealthy_Rate', 'Avg_Probability', 'Avg_Premium']\n",
    "    risk_analysis.reset_index().to_excel(writer, sheet_name='Risk Band Analysis', index=False)\n",
    "\n",
    "print(\"üìÅ Excel file created successfully!\")\n",
    "\n",
    "# Create CSV file for main predictions\n",
    "predictions_df.to_csv('Anova_Insurance_Predictions.csv', index=False)\n",
    "print(\"üìä CSV file created successfully!\")\n",
    "\n",
    "# Download files\n",
    "print(\"\\nüì• DOWNLOADING FILES...\")\n",
    "files.download('Anova_Insurance_Decision_Tree_Results.xlsx')\n",
    "files.download('Anova_Insurance_Predictions.csv')\n",
    "\n",
    "print(\"\\n‚úÖ FILES READY FOR DOWNLOAD!\")\n",
    "print(\"üìÅ Anova_Insurance_Decision_Tree_Results.xlsx - Complete analysis with multiple sheets\")\n",
    "print(\"üìä Anova_Insurance_Predictions.csv - Detailed predictions data\")\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\nüéØ FINAL MODEL SUMMARY:\")\n",
    "print(f\"Model Performance: {final_results['accuracy']:.1%} accuracy, {final_results['recall']:.1%} recall\")\n",
    "print(f\"Risk Management: {final_results['false_negative_rate']:.1%} false negative rate\")\n",
    "print(f\"Business Impact: 3 risk bands, premium range ${risk_band_df['Annual_Premium'].min():.0f}-${risk_band_df['Annual_Premium'].max():.0f}\")\n",
    "print(f\"Interpretability: {len(business_rules)} business rules generated\")\n",
    "print(f\"\\nüöÄ Model ready for Anova Insurance deployment!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}